{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85534d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved as 'math3_estimator.joblib'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from joblib import dump\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load training dataset\n",
    "df = pd.read_csv(\"../train_dataset.csv\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df = df.drop(columns=['Student ID', 'Mentor-1', 'Mentor-2', 'Mentor-3', 'Roll-2', 'Roll-3',\n",
    "                      'DE Theory', 'DE Practical', 'FSD Theory', 'FSD Practical',\n",
    "                      'Python Theory', 'Python Practical', 'Communication Theory', 'Law Theory'])\n",
    "\n",
    "# Feature Engineering\n",
    "sem1_columns = ['Math-1 Theory', 'Physics Theory', 'Java-1 Theory', 'Software Engineering Theory']\n",
    "sem2_columns = ['Math-2 Theory', 'Data Structures using Java Theory', 'DBMS Theory',\n",
    "                'Fundamental of Electronics and Electrical Theory', 'Java-2 Theory']\n",
    "\n",
    "df['Sem 1 Percentage'] = df[sem1_columns].mean(axis=1).round(2)\n",
    "df['Sem 2 Percentage'] = df[sem2_columns].mean(axis=1).round(2)\n",
    "\n",
    "# Rename and extract section letters\n",
    "df = df.rename(columns={'Div-1': 'Section-1', 'Div-2': 'Section-2', 'Div-3': 'Section-3'})\n",
    "for section in ['Section-1', 'Section-2', 'Section-3']:\n",
    "    df[section] = df[section].astype(str).str[0]\n",
    "\n",
    "# Prepare features and target\n",
    "target_col = 'Math-3 Theory'\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "categorical_cols = ['Gender', 'Religion', 'Branch', 'Section-1', 'Section-2', 'Section-3']\n",
    "numeric_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', RobustScaler(), numeric_cols)\n",
    "])\n",
    "\n",
    "# Base pipelines for tuning\n",
    "ridge_pipeline = Pipeline([('preprocessor', preprocessor), ('regressor', Ridge())])\n",
    "lasso_pipeline = Pipeline([('preprocessor', preprocessor), ('regressor', Lasso(max_iter=10000))])\n",
    "elastic_pipeline = Pipeline([('preprocessor', preprocessor), ('regressor', ElasticNet(max_iter=10000))])\n",
    "\n",
    "# Cross-validation strategy\n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "# Search spaces\n",
    "param_space = {\n",
    "    'ridge': {'regressor__alpha': (1e-3, 1e3, 'log-uniform')},\n",
    "    'lasso': {'regressor__alpha': (1e-3, 1e3, 'log-uniform')},\n",
    "    'elastic': {\n",
    "        'regressor__alpha': (1e-3, 1e3, 'log-uniform'),\n",
    "        'regressor__l1_ratio': (0.05, 1.0, 'uniform')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Hyperparameter search\n",
    "ridge_search = BayesSearchCV(ridge_pipeline, param_space['ridge'], n_iter=50, cv=kf,\n",
    "                             scoring='neg_mean_absolute_error', random_state=42)\n",
    "ridge_search.fit(X, y)\n",
    "\n",
    "lasso_search = BayesSearchCV(lasso_pipeline, param_space['lasso'], n_iter=50, cv=kf,\n",
    "                             scoring='neg_mean_absolute_error', random_state=42)\n",
    "lasso_search.fit(X, y)\n",
    "\n",
    "elastic_search = BayesSearchCV(elastic_pipeline, param_space['elastic'], n_iter=50, cv=kf,\n",
    "                               scoring='neg_mean_absolute_error', random_state=42)\n",
    "elastic_search.fit(X, y)\n",
    "\n",
    "# Final ensemble regressor\n",
    "ensemble_model = VotingRegressor([\n",
    "    ('ridge', ridge_search.best_estimator_['regressor']),\n",
    "    ('lasso', lasso_search.best_estimator_['regressor']),\n",
    "    ('elastic', elastic_search.best_estimator_['regressor'])\n",
    "])\n",
    "\n",
    "# Final pipeline: preprocess + ensemble\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('ensemble', ensemble_model)\n",
    "])\n",
    "\n",
    "# Fit final pipeline\n",
    "full_pipeline.fit(X, y)\n",
    "\n",
    "# Save complete pipeline\n",
    "dump(full_pipeline, \"math3_estimator.joblib\")\n",
    "print(\"Model training complete and saved as 'math3_estimator.joblib'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e3fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction failed: Pipeline is not fitted yet.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Plot Actual vs Predicted\u001b[39;00m\n\u001b[32m     26\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m plt.scatter(y_test, \u001b[43my_pred\u001b[49m, alpha=\u001b[32m0.7\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mPredicted vs Actual\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     28\u001b[39m plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \u001b[33m'\u001b[39m\u001b[33mr--\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mPerfect Prediction\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     29\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mActual Values\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_pred' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math3_predictor import predict_math3  # Assuming your logic is in this file\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"../test_dataset.csv\")\n",
    "\n",
    "# Confirm the target exists\n",
    "target_col = 'Math-3 Theory'\n",
    "if target_col not in test_df.columns:\n",
    "    raise ValueError(f\"'{target_col}' column not found in test dataset.\")\n",
    "\n",
    "# Store y_test\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# Get predictions using your black-box wrapper (which handles preprocessing + dropping target)\n",
    "try:\n",
    "    y_pred = predict_math3(test_df)  # <-- Pass full test_df, NOT X_test\n",
    "    print(\"Prediction completed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Prediction failed: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, label='Predicted vs Actual')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Perfect Prediction')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Ensemble Model Predictions on Test Data')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot\n",
    "output_filename = \"math_model_performance.png\"\n",
    "try:\n",
    "    plt.savefig(output_filename)\n",
    "    print(f\"Plot saved successfully as '{output_filename}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving plot: {e}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculate MAE\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "print(f\"Test MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025b094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
