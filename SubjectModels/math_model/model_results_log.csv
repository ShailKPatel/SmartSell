Model,Approach,MAE
Multiple Linear Regression(MSE loss),multivariate regression + 5-Fold cv + one-hot encoding,6.6619
Quantile Regression (MAE loss),"q=0.5, 5-Fold CV + one-hot encoding",6.7859
Multiple Linear Regression (MSE loss High VIF columns dropped),Multivariate regression + 5-Fold CV + one-hot encoding,6.6735
Quantile Regression (MAE loss High VIF columns dropped),"q=0.5, 5-Fold CV + one-hot encoding",6.7705
Polynomial Regression (Order 2),5-Fold CV + one-hot encoding + degree 2,29.1336
Polynomial Regression (Order 2),5-Fold CV + one-hot encoding + degree 2 + high VIF columns dropped,30.449
Polynomial Regression (Order 3),5-Fold CV + one-hot encoding + degree 3,16.6254
Polynomial Regression (Order 3),5-Fold CV + one-hot encoding + degree 3 + high VIF columns dropped,17.1186
Polynomial Regression (Order 4),5-Fold CV + one-hot encoding + degree 4,15.5107
Polynomial Regression (Order 4),5-Fold CV + one-hot encoding + degree 4 + high VIF columns dropped,15.5209
Support Vector Regression (RBF),5-Fold CV + one-hot encoding + StandardScaler,8.2742
Support Vector Regression (RBF),5-Fold CV + one-hot encoding + StandardScaler + RBF kernel + high VIF columns dropped,8.285
Random Forest Regressor,Full-feature regression with 5-Fold CV and OneHotEncoding,6.8736
Random Forest Regressor (Tuned),"{'regressor__n_estimators': 200, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 2, 'regressor__max_features': 'sqrt', 'regressor__max_depth': 20}",6.8051
Random Forest Regressor (Tuned),"{'regressor__n_estimators': 1000, 'regressor__min_samples_split': 5, 'regressor__min_samples_leaf': 4, 'regressor__max_features': None, 'regressor__max_depth': None}",6.8434
Random Forest Regressor (Tuned),"{'regressor__n_estimators': 500, 'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 3, 'regressor__max_features': 0.5, 'regressor__max_depth': None}",6.7528
Random Forest Regressor (Tuned),"{'regressor__n_estimators': 500, 'regressor__min_samples_split': 5, 'regressor__min_samples_leaf': 2, 'regressor__max_features': 'sqrt', 'regressor__max_depth': 20}",6.7841
Random Forest Regressor (Tuned),"{'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 0.5, 'max_depth': 30}",6.7535
Random Forest Regressor (Tuned),"{'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 3, 'regressor__max_features': 'sqrt', 'regressor__max_depth': 30}",6.7768
Random Forest Regressor (Tuned),"{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 0.3, 'max_depth': 15}",6.7025
XGBoost Regressor,"Full-feature regression, engineered Sem1/Sem2 %",7.2612
XGBoost Regressor,"Tuned (Best Params: {'regressor__colsample_bytree': 0.9, 'regressor__learning_rate': 0.05, 'regressor__max_depth': 3, 'regressor__n_estimators': 100, 'regressor__subsample': 0.9})",6.672
